{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-11T06:30:51.355878Z",
     "start_time": "2024-12-11T06:30:44.101859Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import logging\n",
    "from notebooks.functions import BasicDataDHandelFunctions\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# For handling warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "file_path = '../data/sample.csv'\n",
    "df = BasicDataDHandelFunctions.load_dataset(file_path)"
   ],
   "id": "dca255cd9a93d96d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature Creation - Derived Features\n",
    "def week_of_month(date):\n",
    "    \"\"\"Returns the week number within the month for a given date.\"\"\"\n",
    "    first_day_of_month = date.replace(day=1)\n",
    "    return (date.day + first_day_of_month.weekday()) // 7 + 1\n",
    "\n",
    "def create_derived_features(df):\n",
    "    \"\"\"Creates new features based on existing ones.\"\"\"\n",
    "    if 'price' in df.columns and 'quantity' in df.columns:\n",
    "        df['total_sales'] = df['price'] * df['quantity']\n",
    "        logging.info(\"Created 'total_sales' feature as price * quantity.\")\n",
    "    else:\n",
    "        logging.warning(\"Columns 'price' or 'quantity' not found for derived feature creation.\")\n",
    "    \n",
    "    if 'date' in df.columns:\n",
    "        df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "        df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "        df['week_number'] = pd.to_datetime(df['date']).dt.isocalendar().week\n",
    "        df['day_of_week_year'] = pd.to_datetime(df['date']).dt.dayofweek\n",
    "        df['day_of_week_month'] = pd.to_datetime(df['date']).apply(week_of_month)\n",
    "        logging.info(\"Extracted 'year', 'month', and 'day_of_week' from 'date'.\")\n",
    "    else:\n",
    "        logging.warning(\"Column 'date' not found for date-based feature extraction.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if df is not None:\n",
    "    df = create_derived_features(df)\n",
    "    display(df.head())\n"
   ],
   "id": "e84a5e28c0978fdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature Transformation - Scaling Numeric Features\n",
    "def scale_numeric_features(df, columns, method='standard'):\n",
    "    \"\"\"Scales numeric features using StandardScaler or MinMaxScaler.\"\"\"\n",
    "    scaler = StandardScaler() if method == 'standard' else MinMaxScaler()\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = scaler.fit_transform(df[[col]])\n",
    "            logging.info(f\"Scaled '{col}' using {method} scaling.\")\n",
    "        else:\n",
    "            logging.warning(f\"Column '{col}' not found for scaling.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Specify numeric columns to scale\n",
    "numeric_columns = ['price', 'quantity', 'total_sales']\n",
    "\n",
    "if df is not None:\n",
    "    df = scale_numeric_features(df, numeric_columns, method='standard')\n",
    "    display(df.head())\n"
   ],
   "id": "2de8235706069bee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feature Encoding - Categorical Variables\n",
    "def encode_categorical_features(df, columns):\n",
    "    \"\"\"Encodes categorical features using Label Encoding.\"\"\"\n",
    "    le = LabelEncoder()\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "            logging.info(f\"Encoded categorical column '{col}'.\")\n",
    "        else:\n",
    "            logging.warning(f\"Column '{col}' not found for encoding.\")\n",
    "    return df\n",
    "\n",
    "# Specify categorical columns to encode\n",
    "categorical_columns = ['category', 'day_of_week']\n",
    "\n",
    "if df is not None:\n",
    "    df = encode_categorical_features(df, categorical_columns)\n",
    "    display(df.head())\n"
   ],
   "id": "6ef5a5d5a8f0279c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Text Feature Extraction - TF-IDF Vectorization\n",
    "def extract_text_features(df, text_column, max_features=100):\n",
    "    \"\"\"Extracts text features using TF-IDF Vectorization.\"\"\"\n",
    "    if text_column in df.columns:\n",
    "        vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "        tfidf_matrix = vectorizer.fit_transform(df[text_column].fillna(''))\n",
    "        tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "        logging.info(f\"Extracted TF-IDF features from '{text_column}'.\")\n",
    "        return pd.concat([df.drop(columns=[text_column]), tfidf_df], axis=1)\n",
    "    else:\n",
    "        logging.warning(f\"Column '{text_column}' not found for text feature extraction.\")\n",
    "        return df\n",
    "\n",
    "# Specify text column for TF-IDF extraction\n",
    "text_column = 'description'\n",
    "\n",
    "if df is not None:\n",
    "    df = extract_text_features(df, text_column)\n",
    "    display(df.head())\n"
   ],
   "id": "ca246fda9e77e31d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Automated Feature Selection\n",
    "def select_best_features(df, target_column, num_features=5):\n",
    "    \"\"\"\n",
    "    Selects the best features using ANOVA F-statistic and returns the transformed DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame to process\n",
    "    - target_column: The target column for supervised feature selection\n",
    "    - num_features: Number of top features to select\n",
    "    \n",
    "    Returns:\n",
    "    - Transformed DataFrame with selected features and target column\n",
    "    \"\"\"\n",
    "    if target_column not in df.columns:\n",
    "        logging.error(f\"Target column '{target_column}' not found in DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Perform feature selection\n",
    "    selector = SelectKBest(score_func=f_classif, k=num_features)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    logging.info(f\"Selected top {num_features} features: {list(selected_columns)}\")\n",
    "    \n",
    "    # Create a new DataFrame with the selected features and the target column\n",
    "    df_selected = pd.DataFrame(X_new, columns=selected_columns)\n",
    "    df_selected[target_column] = y.reset_index(drop=True)\n",
    "    \n",
    "    return df_selected\n",
    "\n",
    "# Specify the target column for feature selection\n",
    "target_column = 'target'  # Replace with your actual target column\n",
    "\n",
    "if df is not None and target_column in df.columns:\n",
    "    df_selected = select_best_features(df, target_column, num_features=5)\n",
    "    display(df_selected.head())\n"
   ],
   "id": "8f4403855c4a80b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if df is not None:\n",
    "    BasicDataDHandelFunctions.save_dataset_csv(df)"
   ],
   "id": "2b4683f2729cefe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
